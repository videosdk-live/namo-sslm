# namo-sslm (Coming Soon)

## Introduction
We are excited to open-source **NAMO-SSLM**, small yet powerful real-time multi-modal. The AI landscape is shifting from massive, resource-intensive models to lightweight, optimized small modelsâ€”and for good reason. Small models (like NAMO-SSLM) offer a compelling mix of efficiency, speed, and cost-effectiveness, making them the smarter choice for real-world applications.

Key research includes:
1. **Run on CPU**: Run model real-time on consumer CPU devices 
2. **Multimodal (voice + vision)**: Native support for real-time speech and vision and OCR capabilites.
3. **Low Latency, Real-Time Processing**: Real-time streaming support with end to end latency as low as 80ms.
4. **Multilingual Support**: Enable multi-lang and hybrid language capabilities such as hing-lish. 


[video]

## Updates
**21.03.2025**: Launched first version. 




